{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c77c50",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b4d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Complete\n"
     ]
    }
   ],
   "source": [
    "# From Imports\n",
    "from math import log, sqrt, pi, exp\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, date\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from scipy.optimize import minimize\n",
    "from arch import arch_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Alias Imports\n",
    "import numpy_financial as npf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pmdarima as pm\n",
    "\n",
    "# Imports\n",
    "import math\n",
    "import arch\n",
    "import openpyxl \n",
    "import pprint\n",
    "\n",
    "print(\"Import Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f8e92",
   "metadata": {},
   "source": [
    "# Importing Uniswap Pool, LP, and USDC Lending Rate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_100bp = []  \n",
    "volumes_100bp = [] #total $USD volume of USDC and ETH traded on each block\n",
    "avg_LP_spread_100bp = [] #probably need an intermediate step to calc this, avg_LP_upper - avg_LP_lower on each block interval\n",
    "active_liq_depth_100bp = [] # sum(x) * sum (y), where the sums are based on the LP positions that contain the current price in their range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc216f22",
   "metadata": {},
   "source": [
    "# Predicted Loss Function Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa29a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "#Used to calculate alpha_lu, alpha_d, and alpha_0\n",
    "def alpha_t(k, Z, Zl, Zu)\n",
    "        if Zl < Z < Zu\n",
    "            xi = k * (Z**(1/2) - (Zl)**(1/2))\n",
    "            yi = k * (Z**(-1/2) - Zu**(-1/2))\n",
    "            alpha = xi + yi * Z\n",
    "        elif Z < Zl:\n",
    "            xi = 0\n",
    "            yi = k * ((Zl)**(-1/2) - (Zu)**(-1/2))\n",
    "            alpha = xi + yi * Z\n",
    "        elif Z > Zu:\n",
    "            xi = k * ((Zu)**(1/2) - (Zl)**(1/2))\n",
    "            yi = 0\n",
    "            alpha = xi + yi * Z\n",
    "        return alpha\n",
    "\n",
    "#See denominator or convexity cost\n",
    "def LP_spread_conversion(Z, Zl, Zu):\n",
    "    sigma_u = -2 * (Z**(1/2)) / (Zu**(1/2)) + 2\n",
    "    sigma_l = -2 * (Z**(1/2)) / (Zl**(1/2)) + 2\n",
    "    return sigma_u + sigma_l\n",
    "\n",
    "#Quadratic Variation, needs multiple step ahead forecast, maybe generate 20 forecasts over the short block interval\n",
    "def calc_QV(price_list):\n",
    "    log_returns = np.diff(np.log(price_list))\n",
    "    QV = []\n",
    "    for i in range(10, len(log_returns), 10):\n",
    "        QV.append(np.sum(np.diff(log_returns[i-10:i])**2))\n",
    "    QV = pd.Series(QV)\n",
    "    return QV\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3008f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining calculations\n",
    "#functionally very similar to LVR\n",
    "\n",
    "Integral[alpha_lu / (2 * spread * Z**2) * QV[Z,Z]] + Integral[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae349c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio losses ONLY over here, fix \n",
    "portfolio_losses = []  # Calculate portfolio losses based on simulated_spreads and simulated_vwap\n",
    "daily_profits = []  # Calculate daily profits based on simulated_spreads and simulated_vwap\n",
    "daily_opportunity_cost = []  # Calculate daily opportunity cost\n",
    "total_daily_pnl = []  # Calculate total daily PnL\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    alpha_0 = alpha_t(k, bond_prices[0, 0], bond_prices[0, 0] - simulated_spreads[i, 0] / 2, bond_prices[0, 0] + simulated_spreads[i, 0] / 2)\n",
    "    \n",
    "    portfolio_loss_i = [alpha_0 - alpha_t(k, Z, Zl, Zu) for Z, Zl, Zu in zip(bond_prices[:, 1:], simulated_spreads[i, :] / 2, simulated_spreads[i, :] / 2)]\n",
    "    daily_profits_i = forecasted_spreads * simulated_volumes[i, :] * fee_rate / 2  # Adjust for bid and ask\n",
    "    \n",
    "    # Calculate daily opportunity cost based on your formula\n",
    "    daily_opportunity_cost_i = [integral_formula(alpha_0 - alpha_d, r, dt) for alpha_d, r, dt in zip(portfolio_loss_i, risk_free_rate_data, dt_values)]\n",
    "    \n",
    "    total_daily_pnl_i = np.array(portfolio_loss_i) + np.array(daily_opportunity_cost_i) + daily_profits_i\n",
    "    \n",
    "    portfolio_losses.append(portfolio_loss_i)\n",
    "    daily_profits.append(daily_profits_i)\n",
    "    daily_opportunity_cost.append(daily_opportunity_cost_i)\n",
    "    total_daily_pnl.append(total_daily_pnl_i)\n",
    "\n",
    "portfolio_losses = np.array(portfolio_losses)\n",
    "daily_profits = np.array(daily_profits)\n",
    "daily_opportunity_cost = np.array(daily_opportunity_cost)\n",
    "total_daily_pnl = np.array(total_daily_pnl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544ee15",
   "metadata": {},
   "source": [
    "# Fitting and Forecasting Parameters using TS Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08156beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get TS parameters for optimal ARIMA GARCH model\n",
    "prices_series = []\n",
    "\n",
    "# Define the window size (half of the data)\n",
    "window_size = len(prices_series) // 2\n",
    "\n",
    "# Create lists to store optimal ARIMA and GARCH orders\n",
    "optimal_arima_orders = []\n",
    "optimal_garch_orders = []\n",
    "\n",
    "# Iterate through the data with a sliding window\n",
    "for i in range(0, len(prices_series) - window_size):\n",
    "    # Extract the current window\n",
    "    window = prices_series[i:i + window_size]\n",
    "\n",
    "    # Perform ARIMA modeling to find the optimal order\n",
    "    arima_model = pm.auto_arima(window, suppress_warnings=True)\n",
    "    best_arima_order = arima_model.order\n",
    "    optimal_arima_orders.append(best_arima_order)\n",
    "\n",
    "    # Perform GARCH modeling to find the optimal order\n",
    "    garch_model = arch.arch_model(window, vol='Garch', p=1, q=1)\n",
    "    res = garch_model.fit(disp='off')\n",
    "    best_garch_order = (res.model.p, res.model.q)\n",
    "    optimal_garch_orders.append(best_garch_order)\n",
    "\n",
    "# Now, you have lists of optimal ARIMA and GARCH orders for each window.\n",
    "\n",
    "# Initialize lists to store forecasts and actual prices\n",
    "forecasts = []\n",
    "actual_prices = []\n",
    "\n",
    "# Iterate through the second half of the data for one-step ahead forecasts\n",
    "for i in range(window_size, len(prices_series)):\n",
    "    # Extract the current window for ARIMA-GARCH modeling\n",
    "    current_window = prices_series[i - window_size:i]\n",
    "\n",
    "    # Use the optimal ARIMA and GARCH orders from the lists\n",
    "    best_arima_order = optimal_arima_orders[i - window_size]\n",
    "    best_garch_order = optimal_garch_orders[i - window_size]\n",
    "\n",
    "    # Train the ARIMA-GARCH model using the current window\n",
    "    # Perform one-step ahead forecast\n",
    "    arima_model = pm.ARIMA(order=best_arima_order)\n",
    "    arima_model.fit(current_window)\n",
    "    garch_model = arch.arch_model(current_window, vol='Garch', p=best_garch_order[0], q=best_garch_order[1])\n",
    "    res = garch_model.fit(disp='off')\n",
    "    \n",
    "    # Forecast the next price using ARIMA-GARCH\n",
    "    forecast = arima_model.predict(n_periods=1, return_conf_int=False)\n",
    "    volatility = res.conditional_volatility[-1]\n",
    "    forecast = forecast * np.sqrt(volatility)  # Adjust the forecast with GARCH volatility\n",
    "    forecasts.append(forecast[0])\n",
    "\n",
    "    # Record the actual price for comparison\n",
    "    actual_prices.append(prices_series[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef857be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
